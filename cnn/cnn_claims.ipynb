{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import keras_metrics\n",
    "import tensorflow as tf    \n",
    "from tensorflow import keras \n",
    "import keras_metrics as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the package\n",
    "final_df = pd.read_csv('/project/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract.text_sw</th>\n",
       "      <th>biblio.invention_title.text_sw</th>\n",
       "      <th>claims.claims_sw</th>\n",
       "      <th>yo2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98980</td>\n",
       "      <td>disclosure relates hand control input device c...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>a hand control input device  comprising  a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69824</td>\n",
       "      <td>one aspect present invention directed plant pl...</td>\n",
       "      <td>bacterial spore compositions for industrial uses</td>\n",
       "      <td>a plant or plant part coated with a composi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9928</td>\n",
       "      <td>demonstrative embodiments include apparatuses ...</td>\n",
       "      <td>apparatus  system and method of setting up an ...</td>\n",
       "      <td>a product comprising one or more tangible c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75599</td>\n",
       "      <td>wavelength multiplexing apparatus includes div...</td>\n",
       "      <td>wavelength multiplexing apparatus and method</td>\n",
       "      <td>a wavelength multiplexing apparatus  compris...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95621</td>\n",
       "      <td>first second inputs received first input indic...</td>\n",
       "      <td>method and apparatus for transmitter optimizat...</td>\n",
       "      <td>canceled     a system comprising  one ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   abstract.text_sw  \\\n",
       "0       98980  disclosure relates hand control input device c...   \n",
       "1       69824  one aspect present invention directed plant pl...   \n",
       "2        9928  demonstrative embodiments include apparatuses ...   \n",
       "3       75599  wavelength multiplexing apparatus includes div...   \n",
       "4       95621  first second inputs received first input indic...   \n",
       "\n",
       "                      biblio.invention_title.text_sw  \\\n",
       "0                                            unknown   \n",
       "1   bacterial spore compositions for industrial uses   \n",
       "2  apparatus  system and method of setting up an ...   \n",
       "3       wavelength multiplexing apparatus and method   \n",
       "4  method and apparatus for transmitter optimizat...   \n",
       "\n",
       "                                    claims.claims_sw  yo2  \n",
       "0     a hand control input device  comprising  a ...    0  \n",
       "1     a plant or plant part coated with a composi...    1  \n",
       "2     a product comprising one or more tangible c...    0  \n",
       "3    a wavelength multiplexing apparatus  compris...    0  \n",
       "4          canceled     a system comprising  one ...    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "y = final_df['yo2']\n",
    "X = final_df.drop(columns = 'yo2')\n",
    "X['tac'] = X['biblio.invention_title.text_sw'] + ' ' + X['abstract.text_sw'] + ' ' + X['claims.claims_sw']\n",
    "X['title_abs'] = X['biblio.invention_title.text_sw'] + ' ' + X['abstract.text_sw'] \n",
    "X['title_claims'] = X['biblio.invention_title.text_sw'] + ' ' + X['claims.claims_sw']\n",
    "X['abs_claims'] = X['abstract.text_sw'] + ' ' + X['claims.claims_sw']\n",
    "X['abstract'] = X['abstract.text_sw']\n",
    "X['title'] = X['biblio.invention_title.text_sw']\n",
    "X['claims'] = X['claims.claims_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "trainX, testX, trainy, testy = train_test_split(X['claims'], y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56250,), (56250,), (18750,), (18750,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape,trainy.shape,testX.shape,testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: train_claims.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "\n",
    "def save_dataset(dataset, filename):\n",
    "    dump(dataset, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "    \n",
    "save_dataset([trainX,trainy], 'train_claims.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pydot\n",
    "filename = 'train_claims.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load a clean dataset\n",
    "def load_dataset(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "# calculate the maximum document length\n",
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])\n",
    "\n",
    "# encode a list of lines\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded\n",
    "\n",
    "# define the model\n",
    "def define_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=2, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 100)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=3, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 100)(inputs3)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(500, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                         tf.keras.metrics.Recall(),\n",
    "                                                                        tf.keras.metrics.AUC(curve='ROC')])\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "    plot_model(model, show_shapes=True, to_file='multichannel_claims.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 20826\n",
      "Vocabulary size: 94492\n",
      "(56250, 20826)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20826)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 20826)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 20826)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20826, 100)   9449200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20826, 100)   9449200     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20826, 100)   9449200     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 20825, 32)    6432        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 20824, 32)    9632        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 20823, 32)    12832       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 20825, 32)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20824, 32)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20823, 32)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 10412, 32)    0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 10412, 32)    0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 10411, 32)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 333184)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 333184)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 333152)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 999520)       0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          499760500   concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            501         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 528,137,497\n",
      "Trainable params: 528,137,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "3516/3516 [==============================] - 9137s 3s/step - loss: 1.8778 - precision: 0.2118 - recall: 0.6995 - auc: 0.7744\n",
      "Epoch 2/10\n",
      "3516/3516 [==============================] - 9230s 3s/step - loss: 0.6241 - precision: 0.4383 - recall: 0.8598 - auc: 0.9417\n",
      "Epoch 3/10\n",
      "3516/3516 [==============================] - 8852s 3s/step - loss: 0.4047 - precision: 0.5709 - recall: 0.9233 - auc: 0.9751\n",
      "Epoch 4/10\n",
      "3335/3516 [===========================>..] - ETA: 8:05 - loss: 0.2678 - precision: 0.6934 - recall: 0.9510 - auc: 0.9888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3516/3516 [==============================] - 9453s 3s/step - loss: 0.2244 - precision: 0.7410 - recall: 0.9611 - auc: 0.9912\n",
      "Epoch 6/10\n",
      "3516/3516 [==============================] - 12288s 3s/step - loss: 0.2494 - precision: 0.7342 - recall: 0.9597 - auc: 0.9889\n",
      "Epoch 7/10\n",
      "3516/3516 [==============================] - 17173s 5s/step - loss: 0.2347 - precision: 0.7390 - recall: 0.9597 - auc: 0.9898\n",
      "Epoch 8/10\n",
      "3516/3516 [==============================] - 19290s 5s/step - loss: 0.3186 - precision: 0.7057 - recall: 0.9464 - auc: 0.9840\n",
      "Epoch 9/10\n",
      "1738/3516 [=============>................] - ETA: 1:13:52 - loss: 0.1863 - precision: 0.7848 - recall: 0.9723 - auc: 0.9936"
     ]
    }
   ],
   "source": [
    "# load training dataset\n",
    "trainLines, trainLabels = load_dataset(filename)\n",
    "\n",
    "# create tokenizer\n",
    "tokenizer = create_tokenizer(trainLines)\n",
    "\n",
    "# calculate max document length\n",
    "length = max_length(trainLines)\n",
    "\n",
    "# calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % length)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "\n",
    "# encode data\n",
    "trains_X = encode_text(tokenizer, trainLines, length)\n",
    "print(trains_X.shape)\n",
    "\n",
    "# define model\n",
    "model = define_model(length, vocab_size)\n",
    "\n",
    "class_weights = 1/(trainLabels.value_counts()/len(trainLabels))\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# fit model\n",
    "history = model.fit([trains_X,trains_X,trains_X], array(trainLabels), epochs=10, batch_size=16, class_weight=class_weights)\n",
    "\n",
    "# save the model\n",
    "model.save('model_claims.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
