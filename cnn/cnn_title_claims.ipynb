{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import keras_metrics\n",
    "import tensorflow as tf    \n",
    "from tensorflow import keras \n",
    "import keras_metrics as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the package\n",
    "final_df = pd.read_csv('/project/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract.text_sw</th>\n",
       "      <th>biblio.invention_title.text_sw</th>\n",
       "      <th>claims.claims_sw</th>\n",
       "      <th>yo2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98980</td>\n",
       "      <td>disclosure relates hand control input device c...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>a hand control input device  comprising  a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69824</td>\n",
       "      <td>one aspect present invention directed plant pl...</td>\n",
       "      <td>bacterial spore compositions for industrial uses</td>\n",
       "      <td>a plant or plant part coated with a composi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9928</td>\n",
       "      <td>demonstrative embodiments include apparatuses ...</td>\n",
       "      <td>apparatus  system and method of setting up an ...</td>\n",
       "      <td>a product comprising one or more tangible c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75599</td>\n",
       "      <td>wavelength multiplexing apparatus includes div...</td>\n",
       "      <td>wavelength multiplexing apparatus and method</td>\n",
       "      <td>a wavelength multiplexing apparatus  compris...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95621</td>\n",
       "      <td>first second inputs received first input indic...</td>\n",
       "      <td>method and apparatus for transmitter optimizat...</td>\n",
       "      <td>canceled     a system comprising  one ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   abstract.text_sw  \\\n",
       "0       98980  disclosure relates hand control input device c...   \n",
       "1       69824  one aspect present invention directed plant pl...   \n",
       "2        9928  demonstrative embodiments include apparatuses ...   \n",
       "3       75599  wavelength multiplexing apparatus includes div...   \n",
       "4       95621  first second inputs received first input indic...   \n",
       "\n",
       "                      biblio.invention_title.text_sw  \\\n",
       "0                                            unknown   \n",
       "1   bacterial spore compositions for industrial uses   \n",
       "2  apparatus  system and method of setting up an ...   \n",
       "3       wavelength multiplexing apparatus and method   \n",
       "4  method and apparatus for transmitter optimizat...   \n",
       "\n",
       "                                    claims.claims_sw  yo2  \n",
       "0     a hand control input device  comprising  a ...    0  \n",
       "1     a plant or plant part coated with a composi...    1  \n",
       "2     a product comprising one or more tangible c...    0  \n",
       "3    a wavelength multiplexing apparatus  compris...    0  \n",
       "4          canceled     a system comprising  one ...    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "y = final_df['yo2']\n",
    "X = final_df.drop(columns = 'yo2')\n",
    "X['tac'] = X['biblio.invention_title.text_sw'] + ' ' + X['abstract.text_sw'] + ' ' + X['claims.claims_sw']\n",
    "X['title_abs'] = X['biblio.invention_title.text_sw'] + ' ' + X['abstract.text_sw'] \n",
    "X['title_claims'] = X['biblio.invention_title.text_sw'] + ' ' + X['claims.claims_sw']\n",
    "X['abs_claims'] = X['abstract.text_sw'] + ' ' + X['claims.claims_sw']\n",
    "X['abstract'] = X['abstract.text_sw']\n",
    "X['title'] = X['biblio.invention_title.text_sw']\n",
    "X['claims'] = X['claims.claims_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainy, testy = train_test_split(X['title_claims'], y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56250,), (56250,), (18750,), (18750,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape,trainy.shape,testX.shape,testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: train_title_claims.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "\n",
    "def save_dataset(dataset, filename):\n",
    "    dump(dataset, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "    \n",
    "save_dataset([trainX,trainy], 'train_title_claims.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pydot\n",
    "filename = 'train_title_claims.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 20836\n",
      "Vocabulary size: 95587\n",
      "(56250, 20836)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20836)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 20836)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 20836)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20836, 100)   9558700     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20836, 100)   9558700     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20836, 100)   9558700     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 20835, 32)    6432        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 20834, 32)    9632        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 20833, 32)    12832       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 20835, 32)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20834, 32)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20833, 32)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 10417, 32)    0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 10417, 32)    0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 10416, 32)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 333344)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 333344)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 333312)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1000000)      0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          500000500   concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            501         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 528,705,997\n",
      "Trainable params: 528,705,997\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "3516/3516 [==============================] - 8716s 2s/step - loss: 1.5523 - precision: 0.2135 - recall: 0.6921 - auc: 0.7756\n",
      "Epoch 2/10\n",
      "3516/3516 [==============================] - 8733s 2s/step - loss: 0.3237 - precision: 0.6163 - recall: 0.9399 - auc: 0.9839\n",
      "Epoch 4/10\n",
      "3516/3516 [==============================] - 8745s 2s/step - loss: 0.2418 - precision: 0.6940 - recall: 0.9555 - auc: 0.9905\n",
      "Epoch 5/10\n",
      "3516/3516 [==============================] - 9039s 3s/step - loss: 0.1853 - precision: 0.7671 - recall: 0.9708 - auc: 0.9937\n",
      "Epoch 7/10\n",
      " 188/3516 [>.............................] - ETA: 2:23:19 - loss: 0.1449 - precision: 0.7929 - recall: 0.9759 - auc: 0.9969"
     ]
    }
   ],
   "source": [
    "# load a clean dataset\n",
    "def load_dataset(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "# calculate the maximum document length\n",
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])\n",
    "\n",
    "# encode a list of lines\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded\n",
    "\n",
    "# define the model\n",
    "def define_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=2, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 100)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=3, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 100)(inputs3)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(500, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                         tf.keras.metrics.Recall(),\n",
    "                                                                        tf.keras.metrics.AUC(curve='ROC')])\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "    plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model\n",
    "\n",
    "# load training dataset\n",
    "trainLines, trainLabels = load_dataset(filename)\n",
    "\n",
    "# create tokenizer\n",
    "tokenizer = create_tokenizer(trainLines)\n",
    "\n",
    "# calculate max document length\n",
    "length = max_length(trainLines)\n",
    "\n",
    "# calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % length)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "\n",
    "# encode data\n",
    "trains_X = encode_text(tokenizer, trainLines, length)\n",
    "print(trains_X.shape)\n",
    "\n",
    "# define model\n",
    "model = define_model(length, vocab_size)\n",
    "\n",
    "class_weights = 1/(trainLabels.value_counts()/len(trainLabels))\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# fit model\n",
    "history = model.fit([trains_X,trains_X,trains_X], array(trainLabels), epochs=10, batch_size=16, class_weight=class_weights)\n",
    "\n",
    "# save the model\n",
    "model.save('model_title_claims.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
